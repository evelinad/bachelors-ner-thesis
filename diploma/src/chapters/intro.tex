\chapter{Introducere}
\label{chapter:intro}

\section{Contextul Problemei}

\subsection{Procesarea Limbajului Natural}

Procesarea Limbajului Natural (eng. Natural Language Processing - NLP \abbrev{NLP}{Natural Language Processing}) este un domeniu din Sțiința Calculatoarelor (eng. Computer Science , CS \abbrev{CS}{Computer Science}), mai exact din Inteligența Artificială și Lingvistică. Multe probleme din NLP implica înțelegerea limbajului uman, adica să permită calculatoarelor sa extragă informație (să înțeleagă) limbajul pe care îl primeesc de la un om în forma sa naturală, nestructurată. Astfel, Procesarea Limbajului Natural este legată oarecum de Interacțiunea Om-Calculator (eng. Human–Computer Interaction).
\abbrev{HCI}{Human–Computer Interaction}

Extragera de Informații (eng. Information Extraction - IE \abbrev{IE}{Information Extraction}) este task-ul unui calculator de a extrage automat informații cu strucutură dintr-un text care nu are structură, dar care poate fi citit de o mașină. Deși procesarea limbajului natural se ocupă si de procesarea de limbaj vorbit, dificultățile suplimentare introduse de acest lucru (Speech to Text) au făcut ca problema de față să fie extensiv studiată pe texte scrise, texte ușor de citit de o mașină, însă greu de interpretat semantic (de înțeles).


\subsection{Ușor pentru Oameni. Dificil pentru Calculatoare}

Procesarea Limbajului Natural are multe task-uri care sunt foarte ușoare pentru oameni, dar sunt dificile pentru mașinile cu tehnologia actuală. Dintre acestea, putem enumera extragerea conceptelor, sumarizarea, extragerea ideilor principale dintr-un text, dialogul cu o altă persoană umană (reprzintă chiar Testul Turing), răspunsul la intrebări și altele.

O mașină poate efectua de milioane de ori mai repede decât un om calcule matematice cu o precizie impresionantă, poate face lucruri pe care oamenii sunt incapabili să le facă, poate avea timpi de reacție mult mai buni decât un om. Toate acestea sunt însă posibile deoarece calculatoarele sunt foarte bune la calcule numerice, atunci când ceea ce trebuie să facă este specificat clar, însă au dificultăți mari în a efectua task-uri mai puțin exacte, mai umane.

Chiar și cu timpii săi de reacție de ordinul milisecundelor, de milioane de ori mai încet decât procesoarele actuale, creierul uman rămâne în continuare infailibil în task-uri ce implică gândire, imaginație și alte procese specifice lui. Este de asemenea extrem de eficient. Neuronii din creier lucrează mult mai eficient decât procsoarele actuale, adică nu produc atât de multă căldură.

\index{Amazon Mechanical Turk}
\abbrev{HIT}{Human Intelligence Task}
Există cel puțin o aplicație comercială, care pune la dispoziție \textit{Inteligența umană} pentru rezolvarea de sarcini dificile pentru calculator. Aceasta este \textit{Amazon Mechanical Turk}\footnote{\url{https://www.mturk.com/mturk/}}. Ei definesc HITs (eng. Human Intelligence Tasks), sarcini individuale pe care oamenii le rezolvă. Aceste sarcini sunt banale pentru un om, dar dificile sau aproximative pentru o mașină (de exemplu: recunoașterea entităților cu nume dintr-un text dat). Oamenii sunt remunerați pentru munca depusă, iar companiile care apelează la acest serviciu plătesc bani pentru el și primesc, în schimb, rezovlarea sarcinilor făcute de oameni.

\subsection{Ce este o Entitate cu Nume?}

În lumea aceasta, putem împărți lucrurile în două categorii: continue și discrete. De exemplu, apa și nisipul sunt continue. Pe de altă parte, un scaun sau o mașină sunt obiecte discrete. Acestea sunt \textit{entități}, pentru că pot fi separate. Dar, există poate peste un miliard de scaune în această lume. Un alt exemplu ar fi oamenii. Pe întreaga planetă, există peste 6 miliarde de oameni. Dacă, îi dăm un nume unui om, de exemplu Ion Popescu, atunci el este ușor de de diferențiat de ceilalți oameni, devine distinct. Devine o \textit{entitate cu nume}.

 
Formal, termenul de Entitate cu Nume (eng. Named Entity - NE \abbrev{NE}{Named Entity}) \abbrev{eng.}{Engleză} este des întâlnit în Extragerea de Informații (eng. Information Extraction - IE). El a fost inventat la a șasea Conferință pentru Înțelegerea Mesajelor (eng. Message Understanding Conference - MUC)
\abbrev{MUC}{Message Understanding Conference}, MUC-6. (Grishman \& Sundheim, 1996) \cite{grishman1996}. Aceste conferințe au influențat cercetarea in domeniul IE în anii '90. La acel moment, MUC se concentra pe task-uri de IE în care informația structurată trebuia extrasă din articole din ziar din domeniul militar sau antiterorist.

În definiera sarcinilor IE, oamenii au observat că era esențial să se recunoască unități de informație precum \textbf{nume proprii} ce includeau persoane, organizații și locații. Dacă în fazele inițiale ale formulării problemei, alte entităti (nume proprii) erau considerate ca fiind \textit{Amestecate} (eng. Misc. - Miscellaneous), mai târziu, alte unități informaționale au fost introduse, entități care nu mai se identificau cu conceptul de nume propriu (substantiv propriu), ci aveau o corelare cu \textbf{expresiile numerice}, cum ar fi: dată calendaristică, numeral cardinal, numeral ordinal, timp, unități monetare și procente.


Identificarea referințelor la aceste entități a fost recunoscută ca fiind una dintre sracinilie importante la IE și a fost denumită \textbf{Identificarea Entităților cu Nume} (eng. \textit{Named Entity Recognition} - NER).\abbrev{NER}{Named Entity Recognition}


Înainte ca domeniul NER să fie oficial recunoscut la MUC-6 în 1996, cercetări înrudite au fost făcute pentru identificarea numelor proprii. O lucrare publicată în 1991 de Lisa F. Rau este adesea citată ca punctul de naștere al domeniului.\cite{rau1991}

Pentru mai bine de 20 de ani, o comuniate de cercetători a abordat această problemă, folosind diferite tehnici și a creat soluții pentru a perfecționa sistemele NER.

Ca o definiție, un sistem NER este în esență un sistem care primește ca \textit{input} un text din limaj natural, nestructurat. \textit{Output}-ul său reprezintă informație structurată, formată din entitățile identificate și categorizate din textul dat.

Vasta majoritate a sistemelor propuse până în prezent se împart în două categorii:

\begin{itemize}
\item sisteme bazate pe reguli făcute de mână;
\item sisteme folosesc algoritmi de Învățare Automată (eng. Machine Learning ML \abbrev{ML}{Machine Learning}), bazate pe \textit{modele statistice}.
\end{itemize}


În ambele cazuri, colecții mari de documente trebuie să fie analizate ori pentru a deduce reguli și \textit{pattern}-uri, ori pentru a le putea folosi ca date  de antrenament pentru algoritmii de Învățare Automată. Lingviști specializați trebuie să execute această sarcină importantă, care reprezintă un volum semnficiativ de muncă. Este foarte important ca această sarcină să fie făcută corect, deoarece stă la baza algoritmilor de ML. Fiind destul de anevoios și necesitand lucru manual, acastă sarcină constituie un impediment in construirea și întreținerea unui sistem NER la scară largă.

\subsection{Motivația Recunoașterii Entităților cu Nume}

Așa cum am precizat, este important să putem recunoaște într-un text dat referințele la aceste entități din mai multe motive:

\begin{itemize}
\item Constituie un prim pas în extragerea informației structurate. De exemplu, în extragerea relațiilor, din propoziția "Ion lucrează la McDonald's.", trubie să putem extrage mai intâi Ion - \texttt{PERSOANĂ} și McDonald's \texttt{ORGANIZAȚIE}, ca mai apoi să extragem relația \texttt{worksFor(Ion, McDonald's)}.
\item Putem asocia sentimente (pozitive/negative) unui text. Adesea aceste sentimente sunt cu privire la un produs, o persoană etc. De aceea este necesar să le identificăm în text.
\item Răspunsul la întrebări. Adesea, în a formula un răspuns la întrebări se apelează la NER. De exemplu, la competiția TREC-8 (eng. Text REtrieaval Competition - TREC)\abbrev{TREC}{Text REtrieval Competion}, 80\% din cele 200 de întrebări aveau ca răspuns o entitate cu nume, adică Cine? (persoană), Când? (timp sau dată calendaristică), Unde? (locație).\cite{trec8}
\item Traducerea Entitităților cu Nume dintr-o limbă în alta este recunoscută ca fiind o problemă majoră în Machine Translation, deoarece poate contribui cu până la 10 \% din erorile de traducere (Vilar et al., 2006).\cite{vilar2006}
\end{itemize}

\section{Contribuția în Domeniu}
\label{sec:contribution}

\subsection{Construierea unui Set Semnificativ de Texte - Corpus}
\label{sub-sec:corpus-building}

Am studiat diferitele tehnici deja existente de extragere din text a entităților cu nume. Întrucât limba engleză a fost cel mai extensiv studiată, am decis să incep cu ea. Deoarece vasta majoritate a sistemelor NER actuale folosesc tehnici de Machine Learning, m-am axat pe această tehnică și eu.

Din păcate, așa cum am spus, pentru a putea antrena un algoritm de ML este nevoie de o cantiate semnificativă de text adnotat de mână de un lingvist expert. Aceste colecții de texte se numesc în literatura de specialitate \textit{Corpusuri}.\index{Corpus} În prezent, există mai multe corpsuri pentru limba engleză, adnotate pentru NER, cum ar fi cel cu știrile Reuters din perioada 20-08-1996 - 19-08-1997.\cite{rcv1} Acest corpus conține peste 800,000 de articole de știri. Adnotarea a fost făcută pe un subset din aceste știri și a fost prezentată la CoNLL-2003\cite{conll2003} (eng. Conference on Natural Language Learning \abbrev{CoNLL}{Conference on Natural Language Learning}). Primul corpus adnotat cu entități cu nume este cel al conferinței MUC-6 (eng. Message Understanding Conference) și constă în articole din Wall Street Journal din perioada Ianuarie 1993 - Iunie 1994.  Există și alte corpusuri adnotate, însă aproape toate (cel puțin tot ce am găsit eu) sunt cu bani, iar altele nu sunt publice. Așa că eu nu am avut acces la un astfel de corpus adnotat. Cercetări importante au loc și în domeniul biomedical și există și corpusuri adnotate pentru acest domeniu. Dar, este un domeniu mult mai specializat și nu voi insista pe el.

De asemenea, \textit{task}-ul meu consta în identificarea entităților cu nume pe texte din Științe Sociale. Așa cum voi prezenta ulterior, sistemele NER antrenate pe un corpus dintr-un domeniu se comportă foarte prost pe texte dintr-un alt domeniu. Din informațiile pe care le posed, nu s-au făcut adnotări până în prezent pe un astfel de domeniu.

Prin urmare, prima sarcină a fost strângerea unui corpus din domeniul Științelor Sociale. Am folosit pentru aceasta două motoare de căutare de documente științifice - PDF-uri:

\begin{itemize}
\item Google Scholar; \footnote{\url{http://scholar.google.ro/}} "Stand on the shoulders of giants";
\item Microsoft Academic Search. \footnote{\url{http://academic.research.microsoft.com/}}
\end{itemize}

Voi descrie în \labelindexref{Secțiunea}{sec:web-module} cum am făcut strângerea automată a unui număr semnificativ de documente în format PDF.

\subsection{Adnotarea unui subset din corpusul strâns}

După ce au fost strânse, pdf-urile au fost prelucrate. S-a extras textul din ele, au fost eliminate anumite caractere \textit{neparsabile} și au fost eliminate despărțirile în silabe de la sfârșit de linie, acolo unde bineințeles se putea. Apoi, au fost amestecate și împărțite în bucăți mici de text (50- 100 de linii). Un număr de câteva sute de astfel de \textit{split}-uri a fost adnotat folosind BRAT(Brat Rapid Adnotation Tool)\footnote{\url{http://brat.nlplab.org/}}

Este cunsocut faptul ca procedeul de adnotatare manuală implică un volum mare de muncă și un efort substanțial, consumând destul timp. Am încercat să creez un corpus statistic reprezentativ, adică am adnotat bucăți diferite, de la început, cuprins, sau referințe și de la autori diferiți. Mai multe detalii voi da în \labelindexref{Secțiunea}{section:brat-annotation}, dedicată acestei etape.

\subsection{Antrenarea unui sistem NER pe textele adnotate}

\index{Maximum Entropy Markov Model}
\index{Conditional Random Field}

Folosind corpusul adnotat, am antrenat un sistem de recunoaștere a entităților cu nume pe el. Am folosit mai multe tipuri de \textit{feature}-uri pentru algoritmul de Învățare Automată. Textul natural vine in secvență (cuvânt după cuvânt), așa că am folosit algoritmi de ML bazați pe \textit{sequence labeling} (\textit{tagging}), cum ar fi Modele Markov Ascunse, (eng. Hidden Markov Models - HMM) \abbrev{HMM}{Hidden Markov Model}, care este un model generativ, dar și modele discriminative, mai eficiente, cum ar fi Maximum Entropy Markov Models(MEMM)\abbrev{MEMM}{Maximum-Entropy Markov Model}, dar si Conditional Random Fields(CRF)\abbrev{CRF}{Conditional Random Field}.

Am antrenat mai multe modele folsoind două librării care implementează Conditional Random Fields (CRFs):
\begin{itemize}
\item Stanford CRF Classfier;
\item MALLET(MAchine Learning for LanguagE Toolkit).
\end{itemize}

Mai multe detalii privitoare la antrenarea modelelor pot fi consultate la \labelindexref{Secțiunea}{sub-sec:crf-software}.


Deoarece corpusul adnotat de mine este de dimensiuni relativ mici și are doar un format destul de restrâns, algoritmii testați au tendința de a memora ceea ce văd și nu prea generalizează. Astfel, că pe texte din setul de antrenament, algoritmul se comportă foarte bine - identifică si clasifică cu un scor foarte bun. Dar, pe texte pe care nu le-a văzut, chiar și din același domeniu (set de PDF-uri), acuratețea scade. Mai mult, pe texte din domenii diferite, așa cum era de așteptat, se observă o degradare destul de drastică a performanțelor. Voi prezenta mai multe detalii în \labelindexref{Secțiunea}{sec:model-measurements}.

Mai multe detalii privitoare la performanțele modeleloror și și explicarea arhitecturii sistemului vor fi prezentate în secțiunile corespunzătore.

\section{Structura Lucrării}

În continuare, lucrarea este structurată în următoarele capitole:

\begin{enumerate}

\item Descriere în Detaliu și Cercetări Similare \labelindexref{Capitolul}{chapter:history};
\item Descrierea Arhitecturii Sistemului \labelindexref{Capitolul}{chapter:architecture};
\item Tehnici și Algoritmi Folosiți în implementarea Sistemului \labelindexref{Capitolul}{chapter:algorithms};
\item Statistici și Rezultate Obținute \labelindexref{Capitolul}{chapter:measurements};
\item Concluzii și Cercetări Ulterioare \labelindexref{Capitolul}{chapter:conclusions};
\item Studiu de caz (extindere): Coapariția Entităților cu Nume \labelindexref{Anexa}{chap:entities-cooccurrence}.

\end{enumerate}
