\chapter{Introducere}
\label{chapter:intro}

\section{Contextul Problemei}

\subsection{Procesarea Limbajului Natural}

\abbrev{NLP}{Natural Language Processing}
\abbrev{CS}{Computer Science}

Procesarea Limbajului Natural (eng. Natural Language Processing - NLP) este un domeniu din Sțiința Calculatoarelor (eng. Computer Science - CS), mai exact din Inteligența Artificială și Lingvistică. Multe probleme din NLP implică înțelegerea limbajului uman, adică să permită calculatoarelor sa extragă informație (să înțeleagă) limbajul pe care îl primesc de la un om în forma sa naturală, nestructurată. Astfel, Procesarea Limbajului Natural este legată oarecum de Interacțiunea Om-Calculator (eng. Human–Computer Interaction).

\abbrev{HCI}{Human–Computer Interaction}
\abbrev{IE}{Information Extraction}

Extragera de Informații (eng. Information Extraction - IE) este \textit{task}-ul unui calculator de a extrage automat informații cu structură dintr-un text care nu are structură, dar care poate fi citit de o mașină. Deși procesarea limbajului natural se ocupă și de procesarea de limbaj vorbit, dificultățile suplimentare introduse de acest lucru (Speech to Text) au făcut ca problema de față să fie extensiv studiată pe texte scrise, texte ușor de citit de o mașină, însă greu de interpretat semantic.


\subsection{Ușor pentru Oameni. Dificil pentru Calculatoare}

Procesarea Limbajului Natural are multe \textit{task}-uri care sunt foarte ușoare pentru oameni, dar sunt dificile pentru mașinile cu tehnologia actuală. Dintre acestea, putem enumera extragerea conceptelor, sumarizarea, extragerea ideilor principale dintr-un text, dialogul cu o altă persoană umană (reprezintă chiar Testul Turing), răspunsul la intrebări și altele.

O mașină poate efectua de milioane de ori mai repede decât un om calcule matematice cu o precizie impresionantă, poate face lucruri pe care oamenii sunt incapabili să le facă, poate avea timpi de reacție mult mai buni decât un om. Toate acestea sunt însă posibile deoarece calculatoarele sunt foarte bune la calcule numerice, atunci când ceea ce trebuie să facă este specificat clar, însă au dificultăți mari în a efectua \textit{task}-uri mai puțin exacte, mai umane.

Chiar și cu timpii săi de reacție de ordinul milisecundelor, de milioane de ori mai încet decât procesoarele actuale, creierul uman rămâne în continuare infailibil în task-uri ce implică gândire, imaginație și alte procese specifice lui. Este de asemenea extrem de eficient. Neuronii din creier lucrează mult mai eficient decât procesoarele actuale, adică nu produc atât de multă căldură.

\index{Amazon Mechanical Turk}
\abbrev{HIT}{Human Intelligence Task}
Există cel puțin o aplicație comercială, care pune la dispoziție \textit{Inteligența umană} pentru rezolvarea de sarcini dificile pentru calculator. Aceasta este \textit{Amazon Mechanical Turk}\footnote{\url{https://www.mturk.com/mturk/}}. Ei definesc HITs (eng. Human Intelligence Tasks), sarcini individuale pe care oamenii le rezolvă. Aceste sarcini sunt banale pentru un om, dar dificile sau aproximative pentru o mașină (de exemplu: recunoașterea entităților cu nume dintr-un text dat). Oamenii sunt remunerați pentru munca depusă, iar companiile care apelează la acest serviciu plătesc bani pentru el și primesc, în schimb, rezolvarea sarcinilor făcute de oameni.

\subsection{Ce este o Entitate cu Nume?}

În lumea aceasta, putem împărți lucrurile în două categorii: continue și discrete. De exemplu, apa și nisipul sunt continue. Pe de altă parte, un scaun sau o mașină sunt obiecte discrete. Acestea sunt \textit{entități}, pentru că pot fi separate. Dar, există poate miliarde de scaune în această lume. Un alt exemplu ar fi oamenii. Pe întreaga planetă există peste 6 miliarde de oameni. Dacă îi dăm un nume unui om, de exemplu Ion Popescu, atunci el este ușor de diferențiat de ceilalți oameni, devine \textit{distinct}. Devine o \textit{entitate cu nume}.

\abbrev{NE}{Named Entity}
\abbrev{eng.}{Engleză}
\abbrev{MUC}{Message Understanding Conference}
Formal, termenul de Entitate cu Nume (eng. Named Entity - NE) este des întâlnit în Extragerea de Informații (eng. Information Extraction - IE). El a fost inventat la a șasea Conferință pentru Înțelegerea Mesajelor (eng. Message Understanding Conference - MUC), MUC-6. (Grishman \& Sundheim, 1996) \cite{grishman1996}. Aceste conferințe au influențat cercetarea in domeniul IE în anii '90. La acel moment, MUC se concentra pe task-uri de IE în care informația structurată trebuia extrasă din articole din ziar din domeniul militar sau antiterorist.

În definirea sarcinilor IE, oamenii au observat că era esențial să se recunoască unități de informație precum \textbf{nume proprii} ce includeau persoane, organizații și locații. Dacă în fazele inițiale ale formulării problemei, alte entități (nume proprii) erau considerate ca fiind \textit{Amestecate} (eng. Misc. - Miscellaneous), mai târziu, alte unități informaționale au fost introduse, entități care nu se mai identificau cu conceptul de nume propriu (substantiv propriu), ci aveau o corelare cu \textbf{expresiile numerice}, sau \textbf{expresiile temporale} cum ar fi: dată calendaristică, numeral cardinal, numeral ordinal, timp, unități monetare și procente.


Identificarea referințelor la aceste entități a fost recunoscută ca fiind una dintre sarcinilie importante la IE și a fost denumită \textbf{Identificarea Entităților cu Nume} (eng. \textit{Named Entity Recognition} - NER).\abbrev{NER}{Named Entity Recognition}


Înainte ca domeniul NER să fie oficial recunoscut la MUC-6 în 1996, cercetări înrudite au fost făcute pentru identificarea numelor proprii. O lucrare publicată în 1991 de Lisa F. Rau este adesea citată ca punctul de naștere al domeniului.\cite{rau1991}

Pentru mai bine de 20 de ani, o comuniate de cercetători a abordat această problemă, folosind diferite tehnici și a creat soluții pentru a perfecționa sistemele NER.

Ca o definiție, un sistem NER este în esență un sistem care primește ca \textit{input} un text din limbaj natural, nestructurat. \textit{Output}-ul său reprezintă informație structurată, formată din entitățile identificate și categorisite din textul dat.

Vasta majoritate a sistemelor propuse până în prezent se împart în două categorii:

\abbrev{ML}{Machine Learning}
\begin{itemize}
\item sisteme bazate pe reguli făcute de mână;
\item sisteme care folosesc algoritmi de Învățare Automată (eng. Machine Learning - ML), bazate pe \textit{modele statistice}.
\end{itemize}


În ambele cazuri, colecții mari de documente trebuie să fie analizate ori pentru a deduce reguli și \textit{pattern}-uri, ori pentru a le putea folosi ca date  de antrenament pentru algoritmii de Învățare Automată. Lingviști specializați trebuie să execute această sarcină importantă, care reprezintă un volum semnificativ de muncă. Este foarte important ca această sarcină să fie făcută corect, deoarece stă la baza algoritmilor de ML. Fiind destul de anevoios și necesitând lucru manual, această sarcină constituie un impediment în construirea și întreținerea unui sistem NER la scară largă.

\subsection{Motivația Recunoașterii Entităților cu Nume}

Așa cum am precizat, este important să putem recunoaște într-un text dat referințele la aceste entități din mai multe motive:

\begin{itemize}
\item Constituie un prim pas în extragerea informației structurate. De exemplu, în extragerea relațiilor din propoziția "Ion lucrează la McDonald's.", trebuie să putem extrage mai intâi Ion - \texttt{PERSOANĂ} și McDonald's \texttt{ORGANIZAȚIE}, ca mai apoi să extragem relația \texttt{lucreazăPentru(Ion, McDonald's)}.
\item Putem asocia sentimente (pozitive/negative) unui text. Adesea aceste sentimente sunt cu privire la un produs, o persoană etc. De aceea este necesar să le identificăm în text.
\item Răspunsul la întrebări. Adesea, în a formula un răspuns la întrebări se apelează la NER. De exemplu, la competiția TREC-8 (eng. Text REtrieaval Competition - TREC)\abbrev{TREC}{Text REtrieval Competion}, 80\% din cele 200 de întrebări aveau ca răspuns o entitate cu nume, adică Cine? (persoană), Când? (timp sau dată calendaristică), Unde? (locație).\cite{trec8}
\item Traducerea Entitităților cu Nume dintr-o limbă în alta este recunoscută ca fiind o problemă majoră în Machine Translation, deoarece poate cauza până la 10\% din erorile de traducere (Vilar et al., 2006).\cite{vilar2006}
\end{itemize}

\section{Contribuția în Domeniu}
\label{sec:contribution}

\subsection{Construirea unui Set Semnificativ de Texte - Corpus}
\label{sub-sec:corpus-building}

Au fost studiate diferitele tehnici deja existente de extragere din text a entităților cu nume. Întrucât limba engleză a fost extensiv studiată, am decis să începem cu ea. Deoarece vasta majoritate a sistemelor NER actuale folosesc tehnici de Machine Learning, ne-am axat pe această tehnică și noi.

\abbrev{CoNLL}{Conference on Natural Language Learning}
Din păcate, așa cum am spus, pentru a putea antrena un algoritm de ML este nevoie de o cantiate semnificativă de text adnotat de mână de un lingvist expert. Aceste colecții de texte se numesc în literatura de specialitate \textit{Corpusuri}.\index{Corpus} În prezent, există mai multe corpusuri pentru limba engleză, adnotate pentru NER, cum ar fi cel cu știrile Reuters din perioada 20-08-1996 - 19-08-1997.\cite{rcv1} Acest corpus conține peste 800,000 de articole de știri. Adnotarea a fost făcută pe un subset din aceste știri și a fost prezentată la CoNLL-2003\cite{conll2003} (eng. Conference on Natural Language Learning). Primul corpus adnotat cu entități cu nume este cel al conferinței MUC-6 (eng. Message Understanding Conference) și constă în articole din Wall Street Journal din perioada Ianuarie 1993 - Iunie 1994.  Există și alte corpusuri adnotate, însă aproape toate (cel puțin din ce am găsit noi) nu sunt gratuite, iar altele nu sunt publice. Așa că nu am avut acces la un astfel de corpus adnotat. Cercetări importante au loc și în domeniul biomedical și există și corpusuri adnotate pentru acest domeniu. Dar este un domeniu mult mai specializat și nu vom insista pe el.

De asemenea, \textit{task}-ul complet consta în identificarea entităților cu nume pe texte din Științe Sociale. Așa cum vom prezenta ulterior, sistemele NER antrenate pe un corpus dintr-un domeniu se comportă foarte prost pe texte dintr-un alt domeniu. Din informațiile pe care le avem, nu s-au făcut adnotări până în prezent pe domeniul Științelor Sociale.

Prin urmare, prima sarcină a fost crearea unui corpus din domeniul Științelor Sociale. Am folosit pentru aceasta două motoare de căutare de documente științifice - pdf-uri:

\begin{itemize}
\item Google Scholar\footnote{\url{http://scholar.google.ro/}} "Stand on the shoulders of giants";
\item Microsoft Academic Search.\footnote{\url{http://academic.research.microsoft.com/}}
\end{itemize}

Vom descrie în \labelindexref{Secțiunea}{sec:web-module} cum s-a făcut strângerea automată a unui număr semnificativ de documente în format PDF.

\subsection{Adnotarea unui Subset din Corpusul Creat}

După ce au fost strânse, pdf-urile au fost prelucrate. S-a extras textul din ele, au fost eliminate anumite caractere \textit{neparsabile} și au fost eliminate despărțirile în silabe de la sfârșit de linie, acolo unde bineînțeles se putea. Apoi, au fost amestecate și împărțite în bucăți mici de text (50- 100 de linii). Un număr de câteva sute de astfel de \textit{split}-uri a fost adnotat folosind BRAT(Brat Rapid Adnotation Tool).\footnote{\url{http://brat.nlplab.org/}}

Este cunsocut faptul că procedeul de adnotatare manuală implică un volum mare de muncă și un efort substanțial, consumând destul timp. Am încercat să creăm un corpus statistic reprezentativ, adică am adnotat bucăți diferite, de la început, cuprins, sau referințe și de la autori diferiți. Mai multe detalii vor fi prezentate în \labelindexref{Secțiunea}{section:brat-annotation}, dedicată acestei etape.

\subsection{Antrenarea unui Sistem NER pe Textele Adnotate}

\index{Maximum Entropy Markov Model}
\index{Conditional Random Field}

\abbrev{HMM}{Hidden Markov Model}

Folosind corpusul adnotat, am antrenat un sistem de recunoaștere a entităților cu nume pe el. Am folosit mai multe tipuri de \textit{feature}-uri pentru algoritmul de Învățare Automată. Textul natural vine in secvență (cuvânt după cuvânt), așa că am folosit algoritmi de ML bazați pe \textit{sequence labeling} (\textit{tagging}), cum ar fi Modele Markov Ascunse, (eng. Hidden Markov Models - HMM), care este un model generativ, dar și modele discriminative, mai eficiente, cum ar fi Maximum Entropy Markov Models (MEMM)\abbrev{MEMM}{Maximum-Entropy Markov Model}, dar și Conditional Random Fields (CRF)\abbrev{CRF}{Conditional Random Field}.

Au fost antrenate mai multe modele folosind două librării care implementează Conditional Random Fields (CRFs):
\begin{itemize}
\item Stanford CRF Classifier;
\item MALLET(MAchine Learning for LanguagE Toolkit).
\end{itemize}

Mai multe detalii privitoare la antrenarea modelelor pot fi consultate la \labelindexref{Secțiunea}{sub-sec:crf-software}.


Deoarece corpusul adnotat de noi este de dimensiuni relativ mici și are doar un format destul de restrâns, algoritmii testați au tendința de a memora ceea ce văd și nu prea generalizează. Astfel, că pe texte din setul de antrenament, algoritmul se comportă foarte bine - identifică și clasifică cu un scor foarte bun. Dar pe texte pe care nu le-a văzut, chiar și din același domeniu (set de PDF-uri), acuratețea scade. Mai mult, pe texte din domenii diferite, așa cum era de așteptat, se observă o degradare destul de drastică a performanțelor. Vom prezenta mai multe detalii în \labelindexref{Secțiunea}{sec:model-measurements}.

Mai multe detalii privitoare la performanțele modelelor și explicarea arhitecturii sistemului vor fi prezentate în secțiunile corespunzătoare.

\section{Structura Lucrării}

În continuare, lucrarea este structurată în următoarele capitole:

\begin{enumerate}

\item Descriere în Detaliu și Cercetări Similare \labelindexref{Capitolul}{chapter:history};
\item Descrierea Arhitecturii Sistemului \labelindexref{Capitolul}{chapter:architecture};
\item Tehnici și Algoritmi Folosiți în Implementarea Sistemului \labelindexref{Capitolul}{chapter:algorithms};
\item Statistici și Rezultate Obținute \labelindexref{Capitolul}{chapter:measurements};
\item Concluzii și Cercetări Ulterioare \labelindexref{Capitolul}{chapter:conclusions};
\item Studiu de caz (extindere): Coapariția Entităților cu Nume \labelindexref{Anexa}{chap:entities-cooccurrence}.

\end{enumerate}
