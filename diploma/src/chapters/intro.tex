\chapter{Introducere}
\label{chapter:intro}

\section{Contextul Problemei}

\subsection{Procesarea Limbajului Natural}

Procesarea Limbajului Natural (eng. Natural Language Processing - NLP \abbrev{NLP}{Natural Language Processing}) este un domeniu din Sțiința Calculatoarelor (eng. Computer Science , CS \abbrev{CS}{Computer Science}), mai exact din Inteligența Artificială și Lingvistică. Multe probleme din NLP implica înțelegerea limbajului uman, adica să permita calculatoarelor sa extragă informație (să înțeleagă) limbajul pe care il primeesc de la un om în forma sa naturală, nestructurată. Astfel, Procesarea Limbajului Natural este legată oarecum de Interacțiunea Om-Calculator.

Extragera de Informații (eng. Information Extraction - IE \abbrev{IE}{Information Extraction}) este task-ul unui calculator de a extrage automat informații cu strucutura dintr-un text care nu are structură, dar care poate fi citit de o mașină. Deși procesarea limbajului natural se ocupă si de procesarea de limbaj vorbit, dificultățile suplimentare introduse de acest lucru (Speech to Text) au făcut ca problema de față să fie extensiv studiată pe texte scrise, texte ușori de citit de o mașină, însă greu de interpretat.


\subsection{Ușor pentru Oameni. Dificil pentru Calculatoare}

Procesarea Limbajului Natural are multe task-uri care sunt foarte ușoare pentru oameni, dar sunt dificile pentru mașinile cu tehnologia actuală. Dintre acestea, putem enumera extragerea conceptelor, sumarizarea, extragerea ideilor principale dintr-un text, dialogul cu o altă persoană umană (reprzintă chiar Testul Turing), , răspunsul la intrebări și altele.

O mașină poate efectua de milioane de ori mai repede decât un om calcule matematice cu o precizie impresionantă, poate face lucruri pe care oamenii sunt incapabili să le facă, poate avea timpi de reacție mult mai buni decât un om. Toate acestea sunt însă posibile deoarece calculatoarele sunt foarte bune la calcule numerice, atunci când ceea ce trebuie să faca este specificat clar, însă au dificultăți mari în a efectua task-uri mai puțin exacte, mai umane.


Chiar și cu timpii săi de reacție de ordinul milisecundelor, de milioane de ori mai încet decât procesoarele actuale, creierul uman rămâne în continuare infailibil în task-uri ce implică gândire, imaginație și alte procese specifice lui. Este de asemenea extrem de eficient. Neuronii din crerier lucrează mult mai eficient decât procsoarele actuale, adică nu produc atât de multă caldură.

\subsection{Ce este o Entitate cu Nume?}

În lumea aceasta, putem împărți lucrurile în două categorii: continue și discrete. De exemplu, apa și nisipul sunt continue. Pe de altă parte, un scaun sau o mașină sunt obiecte discrete. Acestea sunt entitați, pentru că pot fi separate. Dar, există poate peste un miliard de scaune în această lume. Un al exemplu ar fi oamenii. Pe întreaga planetă, există peste 6 miliarde de oameni. Dacă, îi dăm un nume unui om, de exemplu Ion Popescu, atunci el este ușor de de diferențiat de ceilalți oameni, devine distinct. Devine o entitate cu nume.

 
Formal, termenul de Entitate cu Nume (eng. Named Entity - NE \abbrev{NE}{Named Entity}) \abbrev{eng.}{Engleză} este des întâlnit în Extragerea de Informații (eng. Information Extraction - IE). El a fost inventat la a șasea Conferință pentru Înțelegerea Mesajelor (eng. Message Understanding Conference - MUC)
\abbrev{MUC}{Message Understanding Conference}, MUC-6. (Grishman \& Sundheim, 1996) \cite{grishman1996}. Aceste conferințe au influențat cercetarea in domeniul IE în anii '90. La acel moment, MUC se concentra pe task-uri de IE în care informația structurată trebuia extrasă din articole din ziar din domeniul militar sau antiterorist.


În definiera sarcinilor IE, oamenii au observat că era esențial sa se recunoască unități de informație precum \textbf{nume proprii} ce includeau persoane, organizații și locații. Dacă în fazele inițiale ale formularii problemei, alte entităti (nume proprii) erau considerate ca fiind Amestecate (eng. Misc.), mai târziu, alte unități informaționale au fost introduse, entități care nu mai se identificau cu conceptul de nume propriu (substantiv propriu), ci aveau o corelare cu \textbf{expresiile numerice}, cum ar fi: data calendaristica, numeral cardinal, numeral ordinal, timp, unități monetare și procente.


Identificarea referințelor la aceste entități a fost recunoscută ca fiind una dintre task-urile importante la IE și a fost denumită \textbf{Identificarea Entităților cu Nume} (eng. \textit{Named Entity Recognition} - NER).\abbrev{NER}{Named Entity Recognition}


Înainte ca domeniul NER să fie oficial recunoscut la MUC-6 în 1996, cercetări înrudite au fost făcute pentru identificarea numelor proprii. O lucrare publicată în 1991 de Lisa F. Rau este adesea citată ca punctul de naștere al domeniului.\cite{rau1991}

Pentru mai bine de 20 de ani, o comuniate de cercetători a abordat această problemă, folosind diferite tehnici și e creat soluții pentru a perfecționa sistemele NER.


Ca o definiție, un sistem NER este în esență un sistem care primește ca input un text din limaj natural, nestrucuturat. Output-ul sau reprezintă informație structurată, formata din entitațile identificate și categorizate din textul dat.


Vasta majoritate a sistemelor propuse până în prezent se împart în două categorii:

\begin{itemize}
\item sisteme bazate pe reguli făcute de mână;
\item sisteme folosesc algoritmi de Învățare Automată (eng. Machine Learning ML \abbrev{ML}{Machine Learning}).
\end{itemize}


În ambele cazuri, colecții mari de documente trebuie să fie analizate ori pentru a deduce reguli și pattern-uri, ori pentru a le putea folosi ca antrenament pt algoritmii de Învățare Automată. Lingviști specializați trebuie să execute această sarcină importantă, care reprezintă un volum semnficiativ de muncă. Este foarte important ca această sarcină să fie făcută corect, deoarece stă la baza algoritmilor de ML. Fiind destul de anevoios și necesitand lucru manual, acastă sarcină constituie un impediement in construirea și întreținerea unui sistem NER la scară largă.

\subsection{Motivația Recunoașterii Entităților cu Nume}

Așa cum am precizat, este important să putem recunoaște într-un text dat referințele la aceste entități din mai multe motive:

\begin{itemize}
\item Constituie un prim pas în extragerea informației structurată. De exemplu, în extragerea relatiilor, din propoziția "Ion lucrează la McDonald's." Trubie sa putem extrage mai intâi Ion - \textit{PERSOANĂ} și McDonald's \textit{ORGANIZAȚIE}, ca mai apoi să extragem relația \texttt{worksFor(Ion, McDonald's)}.
\item Putem asocia sentimente (pozitive/negative) unui text. Adesea aceste sentimente sunt cu privire la un produs, o persoană etc. De aceea este necesar sa le identificăm în text;
\item Răspunsul la întrebări. Adesea, în a formula un răspuns la întrebări se apelează la NER. De exemplu, la competiția TREC-8 (eng. Text REtrieaval Competition - TREC)\abbrev{TREC}{Text REtrieval Competion}, 80\% din cele 200 de întrebări aveau ca răspuns o entitate cu nume, adică Cine? (persoană), Când? (timp sau dată calendaristică), Unde? (locație).\cite{trec8}
\item Traducerea Entitităților cu nume dintr-o limbă în alta este recunoscută ca fiind o problemă majoră în Machine Translation, deoarece poate contribui cu până la 10 \% din erorile de traducere (Vilar et al. 2006).\cite{vilar2006}
\end{itemize}

\section{Contribuția în Domeniu}

\subsection{Construierea unui set semnificativ de texte - Corpus}
Am studiat diferitele tehnici deja existente de extragere din text a entităților cu nume. Întrucât limba engleză a fost cel mai extensiv studiată, am decis să incep cu ea. Deoarece vasta majoritate a sistemelor NER actuale folosesc tehnici de Machine Learning, m-am axat pe aceasta tehnica de și eu.

Din păcate, așa cum am spus pentru a putea antrena un algoritm de ML este nevoie de o cantiate semnificativă de text adnotat de mână de un lingvist expert. Aceste colecții de texte se numesc în literatura de specialitate \textit{Corpusuri}.\index{Corpus} În prezent, există mai multe corpsuri pentru limba engleză, adnotate pentru NER, cum ar fi cel cu știrile Reuters din perioada 20-08-1996, 19-08-1997.\cite{rcv1} Acest corpus conține peste 800,000 de articole de știri. Adnotarea a fost facută pe un subset din aceste știri și a fost prezentată la CoNLL-2003\cite{conll2003} (eng. Conference on Natural Language Learning \abbrev{CoNLL}{Conference on Natural Language Learning}). Primul corpus adnotat cu entități cu nume este cel al conferinței MUC-6 (eng. Message Understanding Conference) și constă în articole din Wall Street Journal din perioada Ianuarie 1993 - Iunie 1994.  Există și alte corpusuri adnotate, însă aproape toate (cel puțin tot ce am găsit eu) sunt cu bani, iar altele nu sunt publice. Așa că eu nu am avut acces la un astfel de corpus adnotat. Cercetări importante au loc și în domeniul biomedical și există si corpusuri adnotate pentru acest domeniu. Dar, este un domeniu mult mai specializat și nu voi insista pe el.

De asemenea, task-ul meu consta în identificarea entităților cu nume pe texte din Științe Sociale. Așa cum voi prezenta ulterior, sistemele NER antrenate pe un corpus dintr-un domeniu se comportă foarte prost pe texte dintr-un alt domeniu. Din informațiile pe care le posed, nu s-au făcut adnotări până în prezent pe un astfel de domeniu.

Prin urmare, prima sarcină a fost strângerea unui corpus din domeniul Științelor Sociale. Am folosit pentru aceasta două motoare de căutare de documente științifice - pdf-uri:

\begin{itemize}
\item Google Scholar; \footnote{\url{http://scholar.google.ro/}} "Stand on the shoulders of giants";
\item Microsoft Academic Search. \footnote{\url{http://academic.research.microsoft.com/}}
\end{itemize}

Voi descrie ulterior cum am făcut strângerea automată a unui număr semnificativ de documente in format PDF.

\subsection{Adnotarea unui subset din corpusul strâns}

După ce au fost strânse, pdf-urile au fost prelucrate. S-a extras textul din ele, au fost eliminate anumite caractere neparsabile și au fost eliminate despărțirile în silabe de la sfârșit de linie, acolo unde bineințeles se putea. Apoi, au fost amestecate și împărțite în bucăți mici de text (50- 100 de linii). Un număr de câteva sute de astfel de split-uri a fost adnotat folosind BRAT(Brat Rapid Adnotation Tool)\footnote{\url{http://brat.nlplab.org/}} Mai multe detalii voi da în secțiunea dedicată acestei etape.

\subsection{Antrenarea unui sistem NER pe textele adnotate}

Folosind corpusul adnotat, am antrenat un sistem de recunoaștere a entităților cu nume pe el. Am folosit mai multe tipuri de feature-uri pentru algoritmul de Învățare Automată. Textul natural vine in secvență (cuvând după cuvânt), așa ca am folosit algoritmi de ML bazate pe sequence labeling (tagging), cum ar fii Modele Markov Ascunse, (eng. Hidden Markov Models - HMM) \abbrev{HMM}{Hidden Markov Model}, care este un model generativ, dar și modele discriminative, mai eficiente, cum ar fi Maximum Entropy Markov Models(MEMM)\abbrev{MEMM}{Maximum-entropy Markov model}, dar si Conditional Random Fields(CRF)\abbrev{CRF}{Conditional Random Field}.


Deoarece corpusul adnotat de mine este de dimensiuni relativ mici și are doar un format destul de restrâns, algoritmii testați au tendința de a memora ceea ce văd și nu prea generalizază. Astfel, ca pe texte din setul de antrenament, algoritmul se comportă foarte bine - identifică si clasifică cu un scor foarte bun. Dar, pe texte pe care nu le-a văzut, chiar și din același domeniu (set de PDF-uri), acuratețea scade. Mai mult, pe texte din domenii diferite, așa cum era de așteptat, se observă o degradare destul de drastică a performanțelor. Voi prezenta mai multe detalii în secțiunea dedicată.

\section{Structura Lucrării}

Lucrarea este structurată in următoarele capitole:

\begin{enumerate}

\item Descriere în detaliu și Cercetări similare (State of The Art)  \labelindexref{Capitolul}{chapter:history};
\item Descrierea Arhitecturii Sistemului \labelindexref{Capitolul 3}{sub-sec:proj-objectives};
\item Implementarea Sistemului \labelindexref{Capitolul 4}{sub-sec:proj-objectives};
\item Concluzii, Observații și Direcții Ulterioare \labelindexref{Capitolul 5}{sub-sec:proj-objectives}.

\end{enumerate}

\todo{Descriu mai bine lucrarea}

\textbf{This is just a demo file. It should not be used as a sample for a thesis.}\\
\todo{Remove this line (this is a TODO)}

\section{Project Description}
\label{sec:proj}

\subsection{Project Scope}
\label{sub-sec:proj-scope}

This thesis presents the \textbf{\project}.

This is an example of a footnote \footnote{\url{www.google.com}}. You can see here a reference to \labelindexref{Section}{sub-sec:proj-objectives}.


The main scope of this project is to qualify xLuna for use in critical systems.


Lorem ipsum dolor sit amet,\cite{grishman1996} consectetur adipiscing elit. Aenean aliquam lectus vel orci malesuada accumsan. Sed lacinia egestas tortor, eget tristiqu dolor congue sit amet. Curabitur ut nisl a nisi consequat mollis sit amet quis nisl. Vestibulum hendrerit velit at odio sodales pretium. Nam quis tortor sed ante varius sodales. Etiam lacus arcu, placerat sed laoreet a, facilisis sed nunc. Nam gravida fringilla ligula, eu congue lorem feugiat eu.

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean aliquam lectus vel orci malesuada accumsan. Sed lacinia egestas tortor, eget tristiqu dolor congue sit amet. Curabitur ut nisl a nisi consequat mollis sit amet quis nisl. Vestibulum hendrerit velit at odio sodales pretium. Nam quis tortor sed ante varius sodales. Etiam lacus arcu, placerat sed laoreet a, facilisis sed nunc. Nam gravida fringilla ligula, eu congue lorem feugiat eu.


\subsection{Project Objectives}
\label{sub-sec:proj-objectives}

We have now included \labelindexref{Figure}{img:report-framework}.

\fig[scale=0.5]{src/img/reporting-framework.pdf}{img:report-framework}{Reporting Framework}


Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean aliquam lectus vel orci malesuada accumsan. Sed lacinia egestas tortor, eget tristiqu dolor congue sit amet. Curabitur ut nisl a nisi consequat mollis sit amet quis nisl. Vestibulum hendrerit velit at odio sodales pretium. Nam quis tortor sed ante varius sodales. Etiam lacus arcu, placerat sed laoreet a, facilisis sed nunc. Nam gravida fringilla ligula, eu congue lorem feugiat eu.

We can also have citations like \cite{iso-odf}.

\subsection{Related Work}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean aliquam lectus vel orci malesuada accumsan. Sed lacinia egestas tortor, eget tristiqu dolor congue sit amet. Curabitur ut nisl a nisi consequat mollis sit amet quis nisl. Vestibulum hendrerit velit at odio sodales pretium. Nam quis tortor sed ante varius sodales. Etiam lacus arcu, placerat sed laoreet a, facilisis sed nunc. Nam gravida fringilla ligula, eu congue lorem feugiat eu.


Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean aliquam lectus vel orci malesuada accumsan. Sed lacinia egestas tortor, eget tristiqu dolor congue sit amet. Curabitur ut nisl a nisi consequat mollis sit amet quis nisl. Vestibulum hendrerit velit at odio sodales pretium. Nam quis tortor sed ante varius sodales. Etiam lacus arcu, placerat sed laoreet a, facilisis sed nunc. Nam gravida fringilla ligula, eu congue lorem feugiat eu.


Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean aliquam lectus vel orci malesuada accumsan. Sed lacinia egestas tortor, eget tristiqu dolor congue sit amet. Curabitur ut nisl a nisi consequat mollis sit amet quis nisl. Vestibulum hendrerit velit at odio sodales pretium. Nam quis tortor sed ante varius sodales. Etiam lacus arcu, placerat sed laoreet a, facilisis sed nunc. Nam gravida fringilla ligula, eu congue lorem feugiat eu.

We are now discussing the \textbf{Ultimate answer to all knowledge}.
This line is particularly important it also adds an index entry for \textit{Ultimate answer to all knowledge}.\index{Ultimate answer to all knowledge}

\subsection{Demo listings}

We can also include listings like the following:

% Inline Listing example
\lstset{language=make,caption=Application Makefile,label=lst:app-make}
\begin{lstlisting}
CSRCS = app.c
SRC_DIR =..
include $(SRC_DIR)/config/application.cfg
\end{lstlisting}

Listings can also be referenced. References don't have to include chapter/table/figure numbers... so we can have hyperlinks \labelref{like this}{lst:makefile-test}.

\subsection{Tables}

We can also have tables... like \labelindexref{Table}{table:reports}.

\begin{center}
\begin{table}[htb]
  \caption{Generated reports - associated Makefile targets and scripts}
  \begin{tabular}{l*{6}{c}r}
    Generated report & Makefile target & Script \\
    \hline
    Full Test Specification & full_spec & generate_all_spec.py  \\
    Test Report & test_report & generate_report.py  \\
    Requirements Coverage & requirements_coverage &
    generate_requirements_coverage.py   \\
    API Coverage & api_coverage & generate_api_coverage.py  \\
  \end{tabular}
  \label{table:reports}
\end{table}
\end{center}