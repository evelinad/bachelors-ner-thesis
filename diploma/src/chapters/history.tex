\chapter{Descriere în Detaliu și Cercetări Similare}
\label{chapter:history}

În acest capitol vom descrie mai în detaliu task-ul NER, vom expune domeniile similare în care NER are aplicații, vom prezenta un istoric al cercetărilor din ultimii 20 de ani din domeniu, vom prezenta provoacările NER și factorii care influențează un sistem NER și vom expune produsele software existente cu tehnologia actuală în prezent - \textit{vârful de lance} - State of the Art.

\section{Definirea formală}

În comunitatea științifică, nu există in momentul de față un acrod clar în definirea unei entități cu nume. Totuși se pot da câteva definiții destul de bune.

Entitățile cu nume sunt expresii care conțin nume de presoane, organizații, locații, timpi și cantități. (eng. "Named entities are phrases that contain the names of persons, organizations, locations, times, and quantities.") (CoNLL-2002)

Definiția dată de CoNLL-2002 este pragmatică în sensul că poate clarifică sarcina NER, a identificării entităților cu nume. Ea limitează entitățile cu nume la conceptele de \texttt{PERSOANĂ}, \texttt{ORGANIZAȚIE}, \texttt{LOCAȚIE}, \texttt{TIMP} și \texttt{CANTITATE}.


\textit{Identificarea Entităților cu Nume} constă in identificarea aparitiilor unor tipuri predefinite de expresii intr-un text. Vom arăta pe un exemplu din Mikheev et al. (1999)\cite{mikheev1999}, care a fost adnotat cu 4 tipuri de entități:\\

\textbf{<Date>}, \textbf{<Person>}, \textbf{<Organization>} și \textbf{<Location>}.\\


On \textbf{<Date>}Jan $13^{th}$\textbf{</Date>}, \textbf{<Person>}John Briggs Jr\textbf{</Person>} contacted
\textbf{<Organization}>Wonderful Stockbrockers Inc\textbf{</Organization>} in\textbf{ <Location>}New
York\textbf{</Location>} and instructed them to sell all his shares in
\textbf{<Organization>}Acme\textbf{</Organization>}.\\

In expresia "Entitate cu nume", cuvântul "nume" rastrânge entitățile doar la acelea pentru care exista indicatori concreți (eng. rigid designators), așa cum îi definește Kripke (1982). Indicatorii concreți include numele proprii, precum și anumiți termeni natural, cum ar fi unele specii biologice sau substanțe.

O extindere general agreată este să se includă și expresii temporale (\texttt{TIMEX}) si expresii numerice (\texttt{NUMEX}.

În continuare, vom utiliza cuvintele entiate și entitate cu nume, alternativ. Ele vor semnfica același lucru în contextul de față.

\subsection{Tipuri de Entități}

Vom începe cu un exemplu ilustrativ, care arată legătura între entități si categorii, concepte. \labelindexref{Figura}{img:entity-concept} de mai jos arată relația intre concepte și entități.\footnote{\url{http://webknox.com/p/named-entity-definition}}


\fig[scale=0.5]{src/img/entity-concept.png}{img:entity-concept}{Relația între concepte și entități}

Astfel, se poate realiza o împărțire în mai multe tipuri de entități. Ce voi prezenta este o împărțire realizata cu o granularitate mare. Se pot realiza împărțiri cu granlurități mult mai fine, adica de exemplu categoria \texttt{PERSON} poate fi impărțită în mai multe subtipuri, de exemplu:

\begin{itemize}
\item politician;
\item sportiv;
\item actor;
\item celbritate.
\end{itemize}


Împărțirea clasică nu împarte categoriile în subcategorii de granularitate mai fină. Ea este următoarea:

\begin{enumerate}
	\item Entități de tip \texttt{ENAMEX} (4 clase, cele clasice)\index{ENAMEX}
	\begin{enumerate}
		\item PERSON;
		\item ORGANIZATION;
		\item LOCATION;
		\item MISC. (alte entităti care nu se încadrează in nicio categorie)
	\end{enumerate}


	\item Entități de tip \texttt{NUMEX} \index{NUMEX};

	\begin{enumerate}
		\item NUMBER (numeral cardinal, număr);
		\item ORDINAL (numeral ordinal, al doilea, primul etc);
		\item PERCENT (procent, de exemplu 25\% 30 procente);
		\item MONEY (de exemplu \$20,000).
	\end{enumerate}
	
		\item Entități de tip \texttt{TIMEX} \index{TIMEX};
	
		\begin{enumerate}
			\item DATE (Dată calendaristică, de exemplu 12.09.2012);
			\item DARATION (de exemplu, seven days, a week);
			\item TIME (de exemplu, 9:00 AM);
			\item SET (de exemplu, daily, weekly, anually).
		\end{enumerate}


\end{enumerate}

\subsection{Entități în alte tipuri de texte}

Majoritatea cercetarii pe NER s-a făcut și se face pe texte scrise. Acest lucru a fost ales pentru a nu introduce și mai multe surse de erori decât sistemul NER le poate comite. Așa cum am precizat, problema poate fi modelată matematic ca \textit{Sequence labeling}. Deoarece scrierea cu majusculă și alte elemente de morfologia și forma cuvintelor sunt folosite ca \textit{feature-uri} pentru identificarea candidaților la entități cu nume, textele scrise au fost studiate extensiv. Ele pastrează informații despre scrierea cuvintelor.

\begin{description}
\item[O primă] primă alternativă a task-ului NER este folosirea vorbirii ca input(Favre et al, 2005).\cite{favre2005} Task-ul este considerat mai dificil deoarece scrierea cu majusculă a cuvintelor este pierdută. De asemenea, cuvintele sunt aproximate de tehnologii de recunaoștere a vorbirii(eng. Automatic Speech Recognition - ASR)\abbrev{ASR}{Automatic Speech Recognition}, care sunt predispuse la erori. Astfel apare propagarea eroriror. Input-ul pentru sistemul NER este astfel degradat din start.

\item[O a doua] alternativă de formulare a problemei NER este folosirea unor pagini scanate ca input. Aceste pagini sunt trecute prin sistemde de recunoaștere a caracterelor (eng. Optical Character Recognition - OCR)\abbrev{OCR}{Optical Character Recognition}. Cum și aceste sisteme introduc erori, problema degradarii input-ului se mainfestă și aici.(Maynard et al., 2002)\cite{maynard2002}

\item[O a treia] alternativă este să se utilizeze documente care au o oarecare sutructură, documente semistrucutrate, de exemplu documente HTML. Se pot extrage informații suplimentare din aceste tipuri de documente. De exemplu, delimitarea entităților poate fi extrasă mai precis pentru că ele pot fi demarcate de tag-ui html, cum ar fi \texttt{<span>}European Union\texttt{</span>}.(Kushmerick, 1997)\cite{kushmerick1997}

\end{description}

\subsection{Tehnici și Algoritmi folosiți în problema NER}

Abilitatea de a reunoaște entități pe care sistemul nu le-a văzut înainte este esențială în preformanța unui sistem NER. O astfel de abilitate se bazează pe recunoașterea și clasificarea de reguli declanșate de diferite feature-uri asocitate atât cu exemple pozitive cât și cu exemple negative. Dacă la început, sistemele NER erau bazate pe reguli acum majoritatea folosesc tehnici avansate de Machine Learning supervizat. 

\todo{Da adugat aici}


\section{Domenii Înrudite și Aplicații NER}

\subsection{Cercetări Similare}

În această secțiune, vom prezenta unele task-uri care au legătură cu NER și pentru care Identificarea Entităților cu Nume are un impact direct. Pentru aceste tak-uri scopul principal nu este identificarea entităților, dar reprezintă un pas intermediar, esențial.

\paragraph{Eliminarea ambiguității numelor (de persoane)}

reprezintă problema identificării corecte a referinței unui identificator dat. De exemplu, Neil Armstrong poate fi:

\begin{itemize}
\item Neil Armstrong (1930–2012), un astronaut American si prima persoană care a pus piciorul pe Lună;
\item Neil Armstrong, jucător canadian de hockey pe gheață;
\item Neil J. Armstrong, aviator.
\end{itemize}

Eliminarea ambiguității este folosită pentru generarea de biografii automate dintr-un corpus de documente. Documentele sunt clusterizate, pentru a elimina ambiguitatea.(Mann \& Yarowski, 2003)\cite{Mann03unsupervisedpersonal}

De asemenea, cercetări ample s-au făcut folosind Wikipedia ca sursă de cunosțințe enciclopedice pentru eliminarea ambiguității. Wikipedia este o enciclopedie liberă online scrisă în mod colaborativ de voluntari. Este o resursă multilimbă. Printre primii care folosesc Wikipedia ca metodă de identificare de entități și de eliminare a ambiguității sunt doi români: Bunescu și Pașca, 2006 \cite{Bunescu06usingencyclopedic}. De atunci, cercetarea în această direcție a continuat să crească și multe lucrări științifice au fost publicate pe această temă, a folosirii Wikipedia pentru eliminarea ambiguității.

\paragraph{Traducerea entităților cu nume}

reprezintă sarcina de a traduce entitățile în mode automat dintr-o limbă în alta. De exemplu "The United States of America" se traduce în română ca "Statele Unite ale Americii". Este cunoscut faptul ca traducerea entităților genereaza până la 10\% din erorile de traducere automată(Vilar et al, 2006) \cite{vilar2006}.

\paragraph{Identificarea acronimelor}

este sarcina de a putea identifica in mod corespunzător definiția corectă a unui acronim. De exemplu, "CS" poate însemna "Computer Science", dar si "Counter-Strike". Rezolvarea  acronimelor este utilă în construirea rețeleore de coreferință. Poate imbunătăți recall-ul informației (procentul de entitați corecte identificate din totalul entităților corecte), prin exapandarea acronimului la semnificația sa originală. Problema este legată de NER deoarece foarte multe nume de organizații sunt date prin acronime: IBM, GE EU etc. (Nadeau \& Tourney, 2005)\cite{Nadeau05asupervised}

\paragraph{Identificarea descrierilor entităților}

este identificarea pasajelor din text care descriu o entitate dată. De exemplu, Traian Băsescu este descris ca "președintele Românieie", sau "șeful de stat al României", ori "liderul de la Cotroceni", în funcție de document. Informațiile din descriere pot fi folosite ca sugestii în eliminarea ambiguităților numelore de persoane.(Radev, 1998)\cite{Radev98learningcorrelations}

\paragraph{Eliminarea coreferințelor pronomiale}

constă în rezolvarea coreferințelor pronomiale prin descoperirea entității la care face referire un pronume. Entitatea a apărut înaintea pronumelui. De exemplu, în textul "Ion este un elev silitor. El studiază la Stanford." , pronumele "El" se referă la "Ion". Are aplicații diverse, de la extinderea identificării descrierilor entităților până la Question Answering - Răspunderea la Întrebări, de exemplu: "Cine a spart geamul?" (Dimitrov et al, 2002)\cite{Dimitrov02alight-weight}

\paragraph{Restauraea capitalizării}

se referă la stabilirea corectă a scrierii cu majusculă sau nu a cuvintelor dintr-un text. De foarte multe ori, în textele din Web-ul social\index{Web Social}, cum ar fi forum-uri, chat-uri, facebook, sau twitter, utilizatorii scriu cu literă mică numele de persoane. De asemenea, acest task este util în Machine Translation, unde o propoziție este tradusă de obicei, fără a ține cont de capitalizare. Totodată, în textele procesate din vorbire, capitalizarea nu este disponibilă. Dându-se o propoziție în care toate cuvintele sunt scrise cu literă mică, scopul este să se restaureze cuvintele care erau scrise cu literă mare.(Agbago et al., 2006)\cite{Agbago06}



\subsection{Aplicații NER}

În această secțiune vom enumera câteva aplicații ale identificării entităților cu nume.

\paragraph{Detecția evenimentelor}

constă în detectarea unor entități temporale alăturate unor alte tipuri de entități. De exemplu, data de naștere a unei persoane și numele ei apar în pereche. Mai mult, deseori apare și locul nașterii, de exemplu: Traian Băsescu (n. 4 noiembrie 1951, Murfatlar). Astfel, se poate extrage informație semantică cum ar fi \texttt{BornAt("Traian Băsescu", "4 noiembrie 1951", "Murfatlar")} (Smith, 2002).\cite{Smith02detectingand}

\paragraph{Răspunderea automată la întrebări}

adesea implică folosirea unor siteme NER in capabilitățile de formulare a răspunsurilor. Foarte multe întrebări sunt formulate astfel încât răspunsul lor să fie o entitate cu nume. De exemplu, "Cine este președintele SUA?". De exemplu, la TREC-8 (Text REtrieval Conference), 80\% din cele 200 de întrebări aveau ca răspuns o entitate cu nume, adică Cine? (persoană), Când? (timp sau dată calendaristică), Unde? (locație).\cite{trec8}

\paragraph{Căutarea semantică de informații}

returnează mai mult decât un răspuns la o întrebare, sau o listă de documente Web. Pentru o interogare (query) dat, sistemul poate întoarce o listă de elemente atunci când query-ul este o categorie de entităti. De exemplu: pentru Mărci telefoane, ar întoarce Nokia, Samsung, HTC, Apple, Sony etc. Sau pentru o entitate concretă va întoarce frații săi apropiați semantic (siblings). De exemplu: pentru query-ul "Facebook", sistemul va întoarce "hi5", "Friendster", "myspace". (Pașca et al., 2004)\cite{pasca2004}

\paragraph{Extragerea de relații}
\label{paragraph:relation}

reprezintă detecția și clasificarea relațiilor semnatice între entități. Are ca prim pas și ca sistem central un sistem de recunoaștere și clasificare a entităților. Este folosită cu precădere în domeniul biomedicinei, cum ar fi relații între:

\begin{itemize}
\item relații între gene și boli; (Chun et. al, 2006)\cite{Chun06extractionof}
\item relații de interactiune între proteine.
\end{itemize}

De asemenea, are și alte aplicații mai puțin specifice. De exemplu, din textul "Bill Gates lucrează la Microsoft" putem extrage relația \texttt{Person-Affiliation(Bill Gates, Microsoft)}.

\paragraph{Text/Web mining}

urmărește extragerea informației dintr-un depozit imens de documente. Are ca scop extragerea de cunoștințe dintr-o cantitate de informații care nu este disponibilă în documente luate în mod izolat, ci in întregul ansamblu de de documente. In lucrarea lui Sanchez și Moreno, entitățile cu nume din domeniul medical sunt extrase dintr-un corpus mare pentru a construi o ontologie\index{Ontologie}. Aceste ontologii pot fi folosite mai departe pentru clasificare de entități și de relații între entități.\cite{sanchez2005}

\section{Provocări ale NER. Factori de Influență}

În această secțiune vom prezenta factorii care influențează performanța unui sistem NER, provocările și obstacolele care fac această sarcină, care la început, sau pentru un neinițiat, ar parea ceva trivial, o sarcină care nu poate fi rezolvata 100\% corect de niciun sistem.


Caracterul intrinsec al problemei NER, care face parte din Procesarea Limbajului Natural (NLP) o face dificilă. Acest lucru are loc deoarece limbajul natural este un limbaj care nu este definit de reguli stricte, este un limbaj care deseori poate fi interpretat în mai multe moduri, care lasă loc de ambiguitate.

În unele limbi cum ar fi chineza, chiar și segmentarea unui text în cuvinte este dificilă pentru că limbajul a fost creat fără separatori de cuvinte. În alte limbi, de exemplu engleza, acest lucru nu constituie un impediment și este aproape 100 \% rezolvabil, asta dacă utilizatorul sau cel care a creat textul nu face greșeli in text. Totuși problema identificării entităților cu nume rămâne una netrivială.

\subsection{Evoluția NER. Scurt Istoric}

Multe strategii au fost propuse de-a lungul scurtei istorii a acestui domeniu, de cam 20 de ani. Este și a fost o istorie scurtă, dar tumultoasă.

Una dintre primele lucrări de cercetare din acest domeniu a fost prezentată de Lisa F. Rau(1991) la a șaptea Conferință IEEE de Aplicații ale Inteligenței Artificiale.\cite{rau1991}. Lucrarea lui Rau descrie un sistem capabil "să extragă și să recunoască nume de companii". Acest sistem a reprezentat pionieratul. El se baza totuși pe reguli făcute de mână și pe euristici. Nu avea nimic care să folosească tehnici de ML, de exemplu.

Din 1991 până în 1995, rata de publicări a râmas relativ scăzută, chiar și în limba engleză. Am reușit să găsesc doar 8 publicații în engleză în acest interval de timp.

Anul 1996 a constituit un punct major de cotitură în istoria NER. Atunci a avut loc primul eveniment major dedicat acestui task, \textbf{MUC-6}(Grishman \& Sundheim, 1996)\footnote{\url{http://cs.nyu.edu/faculty/grishman/muc6.html}}\cite{grishman1996} La această conferința au fost propuse 20 de sisteme de identifacare a entităților cu nume.

Din anul 1996 până în prezent, cercetarea în domeniu s-a accelerat continuu. Nu a existat nicio perioadă în care interesul pentru acest domeniu să scadă. S-a cercetat constant și s-au căutat neîntrerupt soluții inovatoare pentru această problemă netrivială. Au avut loc foarte multe evenimente științifice dedicate acestui domeniu, printre care amintesc CoNLL-2003.\cite{conll2003}

Putem observa, folosind Google books Ngram Viewer \footnote{\url{http://books.google.com/ngrams}}, evoluția de-a lungul timpului a referirilor în literatura de specialitate la cele două denumiri: \textit{named entity} și \textit{named entity recognition} Ea este prezentată în \labelindexref{Figura}{img:ner-evolution}. Se observă că termenii au un caracter accentuat de utilizare și încep să fie folosiți din ce în ce mai mult dupa anii 2000. De asemenea, din grafic reiese ceea ce era și de așteptat, ca termenul \textit{named entity} a apărut în literatura de specialitate înaintea termenului \textit{named entity recognition}.

Acest lucru era de așteptat, deoarece Saul Kripke a introdus noțiunea de indicator rigid (eng. rigid designator) în 1982, iar termenul de "Named Entity Recognition" a fost introdus în literatură mai târziu, la conferința MUC-6 din 1996.\cite{grishman1996}

\fig[scale=0.5]{src/img/ner-evolution.png}{img:ner-evolution}{Evoluția termenilor \textit{named entity} și \textit{named entity recognition} în timp}

Treptat, tehnici de Inteligență Artificială si-au făcut apariția în acest domeniu. Astfel, modelarea matematica ca o problemă de sequence tagging a indreptat cercetarea catre studiul ei folosind Modele Markov Ascunse, într-o primă instanță. Lucrarea lui Bickel, An Algorithm that Learns What's in A Name a fost printre primele lucrări influente care folosesc această abordare. (Bickel et al, 1999)\cite{Bikel99analgorithm}

Apoi, lucrările lu McCallum, Lafferty și Pereira care propuneau nișțe metode pentru evitarea limitărilor HMMM (care este un model generativ) au reprezentat din nou momente cheie. Aceste două lucrări prezentau Maximum Entropy Markov Models (MEMM)(McCallum et al. 2000)\cite{Mccallum00maximumentropy}, respectiv Conditional Random Fields(CRFs)(Lafferty et. al, 2001).\cite{Lafferty01conditionalrandom}. Au folosit multor aplicații din NLP, cum ar fi identificarea părților de vorbire într-un text (eng. Part of Speech Tagging - POS tagging) dar și identificării entităților cu nume. Asta deoarece erau metode pentru sequnce labeling.


\subsection{Influența Limbii}

O proporție covârșitoare din cercetarea în domeniul NER este dedicată studiului limbii engleze. Se întâmplă acest lucru deoarce:

\begin{itemize}
	\item Studiul general NLP este puternic axat pe limba engleză;
	\item Necesitatea identificării entităților cu nume a fost descoperită la MUC(Message Understanding Conferences), conferințe care erau sprijinite de Departamentul de Aparare American. Ele au avut ca scop inițial extragerea de informații din texte din domeniul militar, în care erau relatate crime, atentate etc, cu scopul îmbunătățirii securității SUA;
	\item Limba engleză este o limbă destul de simplă în comparație cu alte limbi. Nu are acord între subiect și predicat, nu are gen pentru substantive și adjective, are reguli bine definite de generare a limbajului în comparație cu alte limbi. Setul de caractere este restrâns la cele 26 de caractere latine standard, etc.;
	\item Corpusurile adnotate cu entități cu nume au fost făcute mai întâi pe articole de știri în limba engleză, Wall Street Journal și Reuters. Deci, pentru algoritmii de ML utilizați în studiul NER, avem un set de date de antrenament de pornire pe această limbă;
	\item Este o limbă de circulație internațională. Chiar și în studiul NER folosind Wikipedia, cele mai multe articole sunt scrise în engleză.
\end{itemize}


O posibilă direcție de cercetare care a apărut în ultimii ani este studiul sistemelor NER independente de limbă (eng. Language Independent NER), sau adresarea problemelor multilingvistice. Cum sistemele de Machine Translation \abbrev{MT}{Machine Translation} sunt și ele departe de a fi perfecte, această problemă a studiului NER pe mai multe limbi, sau în mod independent de limbă nu poate să se bazeze într-un mod robust pe Traducere Automată.

Cu toate acestea, limba germană este studiată la CoNLL-2003\cite{conll2003}. De asemenea, limba franceză beneficiază și ea de interes (Petasis et al., 2001 \cite{Petasis01usingmachine} și Poibeau, 2003 \cite{And03themultilingual}). Limba română este studiată de către Silviu Cucerzan și Yarowsky în 1999 \cite{Cucerzan99languageindependent}. Și alte limbi beneficiază de studiu, printre care merită amintite spaniola, italiana și portugheza (limbi latine), rusa și bulgara (limbi chirilice), chineza, limba coreană (limbi altaice) și limba greacă.

O \textit{observație importantă} ce merită făcută aici este ca ceea ce într-o limbă poate fi considerată entitate cu nume, în altă limba ea nu mai poate fi entitate cu nume, în accepțiunea strictă a \textit{numelor proprii}. Un exemplu ar fi naționalitatea. În limba engleză, naționalitatea este entitate cu nume (clasificată de obicei în categoriea Misc. - Miscellaneous, altele), pentru că se scrie cu majusculă: Dutch, English, American, Canadian, Romanian, etc. În limba română, pe de altă parte, naționalitatea este substantiv comun, iar un sistem NER \textit{clasic} o va ignora, nu o va considera entitate cu nume.

În concluzie, un sistem "language independent", independent de limbă, este dificil de făcut, dându-se diversitatea lingvistică si regulile diferite de sintaxă, morfologie din fiecare limbă. Traducerea automată nu poate rezolva problema deoarece ea însăși este predispusă la erori și este departe de a fi perfectă.


\subsection{Influența Domeniului și a Tipului de Text}

Acești doi factori contribuie semnificativ la limitarea sistemelor NER actuale. 

Un exmplu de împărțire în \textbf{domenii} poate fi dat așa:
\begin{itemize}
	\item domeniu științific, care la rândul lui poate fi divizat în
	\begin{itemize}
		\item fizică;
		\item astronomie;
		\item biomedicină;
		\item știința calculatoarelor;
		\item științe socio-umane etc.
		
	\end{itemize}
	\item afaceri;
	\item sport, etc.	
\end{itemize}

\textbf{Genul} textului poate fi:

\begin{itemize}
	\item gen \textit{formal}. In cadrul acestui tip de text, putem avea alte genuri mai de o granularitate mai mică.  Nu există o diferențiere clară aici între domeniu și gen, aceste două concepte putând să se intersecteze:
	\begin{itemize}
		\item text jurnalistic;
		\item text științific, etc.
	\end{itemize}
	\item gen \textit{informal}. În categoria de text informal putem include textul din:
	\begin{itemize}
		\item discuțiile de e-mail;
		\item discuții de pe forumuri;
		\item discuții de pe chat;
		\item \textit{tweet-uri}.\index{Tweet}
	\end{itemize}
\end{itemize}

În general, se observă că textul \textit{informal} este textul generat de utilizatorii din Web-ul Social\index{Web Social}. Acest tip de text, este dificil de analizat de sistemele NER pentru că adesea nu respectă convențiile limbii în care este scris. De exemplu, numele proprii sunt scrise fără majusculă, se mănâncă des litere, se fac greșeli de ortografie și nu se respectă semnele de punctuație. Există chiar un limbaj propriu, plin de prescurtări și alte notații, caracteristic acestui domeniu de exemplu, cuvântul \texttt{wait} poate fi scris ca \texttt{w8}. Există și o titulatură pentru acest tip de text informal. Ea se numește \textit{Netiquette}. \footnote{\url{http://en.wikipedia.org/wiki/Etiquette_(technology)}}

Împărțirea textului în genuri și domenii, la grade diferite de granularitate, așa cum am văzut că se poate face, complică mult problema NER. Probleme apar din cauza \textit{transferului de vocabular} (eng. Vocabulary Transfer\index{Vocabulary Transfer}. Aceasta câte cuvinte din textul pe care un sistem NER a fost antrenat (și le-a vazut) apar și în textul ce trebuie analizat. De exemplu, dacă antrenăm un sistem NER pe articole din domeniul sportiv și apoi îl punem să analizeze texte din domeniul astronomic, sau biomedical, este foarte probabil ca el să dea peste cuvinte pe care nu le-a văzut deloc. Astfel, el va merge foarte prost. De asemenea, genul joacă un rol important. De pildă, în articolele sțiințifice persoanele apar foarte des ca referințe, de forma (Mayer, S. 2001). Pe de altă parte, în articolele de știri ele apar ca subiect în propoziții, de exemplu "Traian Băsescu a afirmat că...". Un sistem antrenat să recunoască astfel de entitați de tip persoană din articole de știri nu va identifica bine persoanele care apar sub formă de referințe în articolele de cercetare. Această problemă am tratat-o și eu și voi arăta într-un capitol ulterior, cum antrenarea pe un corpus adecvat crește performanțele sistemului NER.


De exemplu, Poibeau și Kosseim, (2001) \cite{Poibeau01propername} au testat unele sisteme de identificare a entităților cu nume pe colectia MUC-6 ce cuprindea articole din ziar (jurnalistice) și pe un corpus propriu făcut din conversații telefonice scrise manual (text \textit{informal}), și pe e-mail-uri tehnice. Ei au raportat o scădere drastică în performanța a sistemelor cuprinsă între 20\% și chiar 40\%, atât în \textit{precizie (eng. precision)} (numărul de entități  găsite și clasificate corect raportat la numărul total de entități) și în \textit{recall}(numarul de entități gasite și clasificate corect raportat la numărul total de entități corecte). Mai multe detalii despre \textit{preczie} și \textit{recall} voi da într-o secțiune ulterioară.


Problema recunoașterii entităților în texte \textit{informale} este abordată recent pe texte din \textit{tweet-uri} prin metode de învățare nesupervizata (K-Nearest Neighbors - KNN \abbrev{KNN}{K-Nearest Neighbors}). Acest clasificator este apoi combinat cu un clasificator supervizat CRF. Această manieră de abordare se numește \textit{semi-supervised} - semisupervizată. Problema clasificatoarelor care folosesc metode nesupervizate este urmatoarea. Chiar dacă la final sunt identificate anumite clase de entități sistemul este incapabil să atribuie nume cu înțeles acestor clase. El va da nume generice, de exemplu C1, C2 etc. Un om trebuie să decidă dacă o clasă este specifică Persoanelor de exemplu.(Liu et al., 2009)\cite{Liu_recognizingnamed}


\subsection{Influența Tipurilor de Entități}

Tipurile de entități pot influența în mai multe moduri performanțele unui sistem de identificare a entitătilor. 

\paragraph{Numărul tipurilori de entități}

influențează sistemele bazate pe ML. Asta deoarece crescând numărul, un calcul matematic simplu arată următorul lucru. Voi calcula probabilitatea medie ca o entitate să fie intr-o anumită clasă. De exemplu, pentru 3 clase, probabilitatea medie este $ P_1 = \frac{1}{3} \simeq 0.33 $. Acest lucru înseamnă că putem foarte ușor să depășim probabiliatea de 50\% ($ \frac{1}{2} $). Adică, putem fi siguri că o entitate cu nume are o apartenență majoritară la clasa respecitvă, aparține cu o certitudine destul de mare. Pe de altă parte, dacă vom crește numărul de clase, de exemplu, la 10 clase, probabilitatea medie va deveni $ P_2 = \frac{1}{10} \simeq 0.1 $. Acest lucru semnifică faptul că este dificil să fim siguri că o entitate aparține cu certitudine (50 \%) la o clasă anume. Sistemul nostru va întoarece un răspuns, cu probabilități, cel mai adesea, sub 0.5 toate. O vom alege pe cea maximă, dar nu va fi majoritară. 

O altă problemă ce apare când creștem numărul de clase este cauzată de creșterea timpului de antrenare al modelului. Cu această problema m-am confruntat de multe ori. Funcția ce trebuie optimizată de algoritmul de ML devine foarte complexă, cu multe variabile, iar costul computațional cresțe cu minim $ O(n^k) $ în funcție de numărul de clase ($n = C)$ pentru că vom vedea că trebuie să ridicăm numărul de clase la puterea ordinului $k$ al modelului secvenței, care este minim 2, adică, în cel ma bun caz vom avea $ O(n^2) $.

Așa cum vom vedea într-o secțiune ulterioară, matematic, în mod concret, dacă avem 3 clase de entități, de exemplu, \texttt{PERSOANĂ}, \texttt{ORGANIZAȚIE}, \texttt{LOCAȚIE}, problema se modelează cu $3 + 1  = 4$ clase. În secvența de cuvinte, fiecarui cuvânt (token)\index{token} i se va asocia o clasă. Cuvintele care nu vor fi entități cu nume, vor avea asociata clasa \texttt{O} - Out, Other. Deci, vom avea practic 4 clase. În general, la $C$ tipuri de entități corespunde un număr de $C + 1$ tipuri de clase. Deci, algortimul nostru, mai rău, va avea de decis între mai multe clase. 

În concluzie, creșterea numărului de tipuri de entități \textit{scade} certitudinea cu care o entitate poate fi prezisă. În practică, această problemă este adresată prin mai multe metode. Una dintre cele mai răspandite metode este ca algoritmul de Învățare Automată să fie antrenat doar pe un număr restrâns de tipuri de entități, pentru restul de tipuri urmând să fie folosite alte tehnici de detecție și clasificare (reguli făcute de mână, cu expresii regulate, cel mai adesea).

\paragraph{Tipurile de Entități} sunt formulate în primele lucrări științifice din domeniul NER ca recunoașterea "numelor proprii" în general. În ansamblu, cele mai  studiate tipuri de entități sunt nume proprii specifice: \texttt{PERSOANE}, \texttt{ORGANIZAȚII}, \texttt{LOCAȚII}. Aceste trei tipuri sunt cunoscute sub titulatura de \texttt{ENAMEX} înca de la competiția MUC-6\cite{grishman1996}.

Se pot face divizări ulterioare la aceste trei tipuri de entități, cu o granularitate din ce în ce mai fină. Spre exemplu, \texttt{LOCATION} poate fi subdivizat în:

\begin{itemize}
\item Oraș;
\item Țară;
\item Continent;
\item Mare;
\item Râu
\item Regiune, etc.
\end{itemize}

Similar, și celelalte două tipuri de entități pot fi divizate astfel. Vom avea persoane la granularitate fină, precum \texttt{Politician}, \texttt{Actor}, etc.

Tipul \texttt{MISC - Miscellaneous - Altele} este introdus la conferințele CoNLL-2002 și CoNLL-2003 \cite{conll2003}. El include tot nume proprii, dar care nu pot fi încadrate in clasicele categorii din standardul \texttt{ENAMEX}, de exemplu naționalități.

\texttt{TIMEX}, care cuprinde categoriile \texttt{TIME} și \texttt{DATE}, printre altele, este de asemenea introdus la MUC-6. Nu în ultimul rând, \texttt{NUMEX} care cuprinde \texttt{NUMBER}, \texttt{MONEY} și \texttt{PERCENT}, printre altele a fost introdus tot la conferința MUC-6.

Deseori, tipurile amintite mai sus din categoriile \texttt{TIMEX} și \texttt{NUMEX} nu sunt incluse în algoritmii de Învățare Automată pentru antrenament. Pentru aceste tipuri sunt create reguli de mână, formate cel mai frecvent din expresii regulate.


Interesul recent din bioinformatică și disponibilitatea corpusului GENIA (Ohta et al., 2002) \cite{Ohta02thegenia}, care curpinde texte adnotate din domeniul biologiei moleculare a condus la multe studii dedicate unor tipuri specifice de entități, cum ar fi \texttt{Protein}, \texttt{Gene} etc. S-au făcut studii exclusiv în acest domeniu pentru identificarea de proteine și de gene noi. De asemenea, așa cum am zis în \labelindexref{Paragraful din Secțiunea}{paragraph:relation}, s-au extras mai departe relații între aceste tipuri de entități.


De remarcat este și lucrul în care nu se limitează tipurile posibile de entități. Astfel, Sekine și Nobata (2004) au definit o ierarhie impresionantă de tipuri de entități cu nume. Această ierarhie include multe subcategorii de granularitate fină, cum ar fi \texttt{Râu}, \texttt{Aeroport} și adaugă de asememenea un număr mare de categorii cum ar fi \texttt{Produs}, \texttt{Substanță}, \texttt{Eveniment}, \texttt{Animal}, \texttt{Culoare} etc. Se încearcă acoperirea celor mai frecvente categorii de tipuri de nume care apar în ziare. Numărul de catgorii ajunge aproape de 200, iar fiecărei categorii i se asociază atribute pentru o construi o ontologie. \index{Ontologie}\cite{sekine2004}

\section{State of The Art}

În această secțiune voi prezenta produsele software și sistemle de recunoaștere a entităților cu nume care există în prezent, atât \textit{open source}\index{open source} și \textit{free}, cât și sistemele comerciale. Acestea reprezintă \textit{vârful de lance} a ceea ce există în momentul de față în domeniu. 

Totuși, chiar și aceste sisteme sunt departe de a fi perfecte. Sistemele \textit{vârf de lance} actuale sunt fragile. Acest lucru este valabil pentru ambele abordări, atât pentru cele bazate pe reguli, cât și pentru cele bazate pe modele statistice. Un sistem NER dezvoltat pentru un domeniu nu se comportă în general bine pe alte domenii.

\subsection{Stanford Named Entity Recognizer}

\index{Stanford Named Entity Recognizer}

Stanford Named Entity  Recognizer\footnote{\url{http://nlp.stanford.edu/software/CRF-NER.shtml}} este poate cel mai cunoscut sistem de recunoaștere a entităților, datorită renumelui pe care îl poartă Stanford și datorită vechimii pe care o are în domeniu. Standord NER face parte din proiectul mai amplu, Stanford NLP \footnote{\url{http://nlp.stanford.edu/}}. Este dezvolat de Stanford Natural Language Processing Group, departament al Universității Stanford. 

Reprezintă o implementare a unui sistem NER în limbajul de programare Java. Este un produs software \textit{open source}.

Are o vechime de aproape șapte ani, având Inital release-ul pe 18 septembrie 2006. La data scrierii articolului, Stanford NLP este la versiunea 3.2.0 (20-06-2013). Din păcate, dependențele Apache Maven nu au fost updat-ate în repository cu versiunea curentă. Astfel, eu am folosit o versiune mai veche a Stanford NLP.

\index{Apache Maven}

Stanford NER folesesțe pentru identificarea entităților cu nume un Conditional Random Field (CRF) antrenat pe diferite corpusuri. Miodelele CRF au fost inventate de Lafferty, McCallum și Pereira în 2001.\cite{Lafferty01conditionalrandom} Modelele generate de antrenarea CRF-ului pe diferitele corpusuri sunt serializate și arhivate. Ele pot fi download-ate separat sau folosite împreuna cu arhiva\textit{.jar} pusă la dispoziție.

\index{Corpus}

Modelele incluse cu care a fost antrenat Stanford NER pentru \textbf{limba engleză} sunt:

\begin{itemize}
\item un model de 4 clase (Location, Person, Organization, Misc) antrenat pentru CoNLL (Retures Corpora);
\item un model de 7 clase (	Time, Location, Organization, Person, Money, Percent, Date) antrenat pentru MUC-6 (Wall Street Journal corpora);
\item un model de 3 clase  (Location, Person, Organization) antrenat atât pe CoNLL cât și pe MUC pentru intersecția dintre cele 2 tipuri de clase.
\end{itemize}

Există modele și pentru alte limbi, cum ar fi limba germană, cât și limba chineză.

De remarcat este faptul că Stanford CRF Classifier poate fi antrenat pe un alt corpus adnotat cu un număr arbitrar de categorii de entități cu nume. Apoi acest model statistic obținut poate fi \textit{serializat} și arhivat pe disc și poate fi folosit de Stanford NER ca și celelalte modele puse la dispoziție in distribuția oficială.

Din păcate, am dorit să obțin scoririle F1 pe care Stanford NER le face pe corpusurile pe care a fost antrenat, dar nu am găsit pe niciunde. Deoarece sistemul a apărut dupa Conferința CoNLL-2003, el nu a participat la competiție. Dacă aș fi avut corpusul, aș fi putut calcula eu scorul F1, dar pentru că nu am avut acces la corpus, nu am avut cum.


\subsection{Apache OpenNLP}

Apache OpenNLP este o librărie de machine learning specializată pe pe procesarea limbajului natural, scrisă în Java. Este de asemenea \textit{open source}.


\index{Apache OpenNLP}
OpenNLP suportă cele mai uzuale task-uri de NLP, cum ar fi token-izarea, segmentarea în propoziții, POS tagging, NER, chunking, parsing și rezolvarea coreferințelor. OpenNLP de asemenea include tool-uri de ML precum Maximum Entropy și Perceptron.\footnote{\url{http://opennlp.apache.org/}}

\index{one-vs-all classification}

Sistemul NER pus la dispoziție de OpenNLP este bazat pe \textit{one-vs-all classification}. Cu alte cuvinte, există câte un model statistic antrenat pentru fiecare clasă în parte. Celelalte clase sunt ignorate în acest model statistic. Adică, modelul care este antrenat să identifice de exemplu \texttt{PERSOANE} va ignora complet celelate categorii de entități, cum ar fi \texttt{LOCAȚII} și \texttt{ORGANIZAȚII}. Le va considera pe toate \texttt{O, Other, Out sau None}.

Astfel, există modele diferite pentru Persoane, Organizații, Locații și Misc.\footnote{\url{http://opennlp.sourceforge.net/models-1.5/}}.

Pentru limba engleză avem 7 modele antrenate fiecare pe câte o clasă din MUC.:

\begin{itemize}
\item model pentru Date, en-ner-date.bin
\item model pentru Location, en-ner-location.bin
\item model pentru Money,	en-ner-money.bin
\item model pentru Organization,	en-ner-organization.bin
\item model pentru Percentage,	en-ner-percentage.bin
\item model pentru Person,	en-ner-person.bin
\item model pentru Time, en-ner-time.bin
\end{itemize}

Această abordare are cu mai mulți clasificatori are avantaje și dezavantaje.

\textit{Avantajele} antrenării mai multor clasificatori sunt următoarele:

\begin{itemize}
	\item Având doar un tip de entitate de recunoscut, avem practic două clase de decis tipul și \texttt{O - None}. Prin urmare, probabiltatea medie este de $P = \frac{1}{2} $. Deci, sistemul nostru poate spune cu certitudine mare apartenența la clasa respectivă, sau nu. Poate foarte ușor să ajungă la o probabilitate de 50\%;
	\item Un singur tip de entitate scade timpul de antrenare a modelului, deoarece funcția ce trebuie optimizată are un număr redus de variabile, având doar o două clase.
\end{itemize}

\textit{Dezavantajul} major al antrenării mai multor clasificatori este reprezentat de distribuția nesimetrică a claselor. Chiar și într-un model cu 3 categorii, numărul de exemple negative, de tip \texttt{O - NONE} domină covârșitor numărul de exemple pozitive, de tip \texttt{PERSON} \texttt{LOCATIO}, etc. Acum, având doar o singură categorie această asimetrie a cauzată de faptul ca numărul de exemple negative este mult mai mare decât numarul de exemple pozitive este și mai pronunțată. Asta deoarece, de exemplu, pentru modelul antrenat pe persoane, toate exemplele pozitive de tip locație, organizație etc, care înainte mai contrabalansau asimetria, vor deveni exemple negative de tip \texttt{O}. Repartiția asimetrică afectează foarte mult acuratețea algoritmului și capacitatea modelului de a recunoaște \textit{cât mai multe} exemple pozitive pe un set de date de test, ceea ce numim \textit{recall}.

De asemenea, Apache OpenNLP pune la dispoziție NER multimbă. Pe lângă engleză, avem modele antrenate pe limba spaniolă și pe limba olandeză, pe 4 clase de la CoNLL-2002.

\subsection{Python NLTK}

\index{Python NLTK}
\index{Corpus}
Python Natural Language Toolkit\footnote{\url{http://nltk.org/}} este platforma de vârf pentru scrierea de programe în limbajul Python care lucrează cu date din limbajul uman. Pune la dispoziție  o colecție impresionantă de peste 50 de corpusuri su resurse de NL{. Are un chiar și un GUI de download pentru modele și corpusuri. În \labelindexref{listing-ul}{lst:python-nltk} de mai jos avem un exemplu de cât de simplu se poate lansa NLTK download-manager-ul. El arată ca în \labelindexref{Figura}{img:nltk-downloader} de mai jos.

% Inline Listing example
\lstset{language=python,caption=Python NLTK,label=lst:python-nltk}
\begin{lstlisting}
>>> import nltk
>>> nltk.download()
\end{lstlisting}

\fig[scale=0.8]{src/img/nltk-downloader.png}{img:nltk-downloader}{GUI-ul pus la dispoziție de Python NLTK}

Din păcate, deși are o colecție impresionantă de corpsuuri, printe ele nu se regăsește și un corpus pe engleză de NER. Putem download-a doar modelele deja antrenate pentru limba engleză. Este pus la dispoziție doar corpusul de antrenament de pe limba olandeză de la CoNLL-2002.

\index{IOB encoding}
\index {IO encoding}
Din ce am putut citi pe site-ul lor, este de remarcat faptul că ei au antrenat modelele pe encodarea de tip \textit{IOB}, nu cea clasică, \textit{IO}. Encoding-ul IOB,  aduce un plus de complexitate. Inseamnă să marchezi diferit începutul unei entități de restul ei. Acest lucru are și avantaje și dezavantaje.


De exemplu, pentru textul "Is John Doe here?", encodările IO și IOB vor fi următoarele:

\begin{center}
\begin{tabular}{ |l | r | r |}
\hline
  Token & Encodare IO & Encodare IOB \\
\hline
  Is & O & O \\
  John & PER & B-PER  \\
  Doe & PER & I-PER \\
  here & O & O \\
  ? & O & O \\
  \hline
\end{tabular}
\end{center}


\textit{Avantajul} pe care îl aduce în plus față de encodarea clasică este că putem delimita  \textit{entitățile consecutive de același tip}. De exemplu, două persoane pot fi delimiate corect. Însă, în practică, delimtarea persoanelor este marcată în text cu virgulă de exemplu, token care va fi etichetat ca exemplu negativ \texttt{O}. Deci delimitarea va fi posibilă fără probleme. Cazurile în care două entități conescutive din aceeși categorie se referă la două obiecte ditincte sunt foarte rare.

\textit{Dezavantajul} este reprezentat de dublarea numărului de clase pentru antrenarea modelului. Adică, dacă înainte pentru $C$ categorii de entități aveam $C + 1 $ clase (trebuia să adaugăm si clasa \txttt{O}, acum numărul lor se dublează pentru fiecare cateogrie de entitate in parte. Asta deoarece avem două clase disincte pentru fiecare categorie \texttt{X}, \texttt{B-X} și \texttt{I-X}, de exemplu pentru \texttt{PERSON} vom avea \texttt{B-PERSON} si \texttt{I-PERSON}. Același lucru e valabil pentru toate cele C categorii, mai puțin pentru clasa \texttt{O}, pentru care nu se va dubla numărul. Deci în encodarea IOB, pentru un număr de $C$ categorii de entități vom avea $2C + 1 $ clase în antrenarea modelului. Astfel, antrenarea modelului va si semnficativ mai lentă, iar probabilitățile mai mici.

\subsection{Alte aplicații}

Există o serie de aplicații comerciale pentru diferite task-uri de Information Extraction. O aplicație interesantă cu care am lucrat, care are și un sistem NER destul de robust, este \textit{AlchemyAPI}.\footnote{\url{http://www.alchemyapi.com/}}.


















